# 📦 মডিউল ইনস্টলেশন গাইড - সম্পূর্ণ বাংলা

## 🎯 এই গাইডে কি আছে?

এই গাইডে আপনি শিখবেন:
- ✅ **সব প্রয়োজনীয় modules** কি কি
- ✅ **Step-by-step installation** process
- ✅ **Virtual environment** setup
- ✅ **Common problems** ও solutions
- ✅ **Module usage examples**

---

## 📋 প্রয়োজনীয় Modules List

### 🎭 **Core Web Scraping:**
```txt
playwright>=1.40.0          # Main web scraping tool
requests>=2.31.0            # HTTP requests
beautifulsoup4>=4.12.0      # HTML parsing
lxml>=4.9.0                 # XML/HTML parser
selenium>=4.15.0            # Alternative browser automation
```

### ⚡ **Async Programming:**
```txt
aiohttp>=3.9.0              # Async HTTP client
aiofiles>=23.2.0            # Async file operations
asyncio-mqtt>=0.16.0        # Async MQTT client
```

### 📊 **Data Processing:**
```txt
pandas>=2.1.0               # Data manipulation
numpy>=1.24.0               # Numerical computing
openpyxl>=3.1.0             # Excel files
xlsxwriter>=3.1.0           # Excel writing
```

### 🖼️ **Image/PDF Processing:**
```txt
Pillow>=10.0.0              # Image processing
reportlab>=4.0.0            # PDF generation
img2pdf>=0.5.0              # Image to PDF
PyPDF2>=3.0.0               # PDF manipulation
opencv-python>=4.8.0        # Computer vision
```

### 🎨 **Visualization:**
```txt
matplotlib>=3.7.0           # Plotting
seaborn>=0.12.0             # Statistical plots
plotly>=5.17.0              # Interactive plots
qrcode[pil]>=7.4.0          # QR code generation
```

### 🛠️ **Utilities:**
```txt
schedule>=1.2.0             # Task scheduling
python-dotenv>=1.0.0        # Environment variables
colorama>=0.4.6             # Colored terminal output
tqdm>=4.66.0                # Progress bars
click>=8.1.0                # Command line interface
```

---

## 🚀 Step-by-Step Installation

### 📁 **Step 1: Project Folder তৈরি**
```bash
# নতুন folder তৈরি করুন
mkdir my-scraping-project
cd my-scraping-project

# অথবা existing folder এ যান
cd your-existing-folder
```

### 🐍 **Step 2: Virtual Environment তৈরি**
```bash
# Virtual environment তৈরি করুন
python -m venv scraping-env

# Activate করুন
# Windows:
scraping-env\Scripts\activate

# Linux/Mac:
source scraping-env/bin/activate

# Activation verify করুন
python --version
pip --version
```

### 📦 **Step 3: Pip Upgrade**
```bash
# Pip upgrade করুন (গুরুত্বপূর্ণ!)
python -m pip install --upgrade pip

# Verify upgrade
pip --version
```

### 📥 **Step 4: Core Modules Install**
```bash
# Core web scraping modules
pip install playwright requests beautifulsoup4 lxml

# Async programming
pip install aiohttp aiofiles

# Data processing
pip install pandas numpy openpyxl

# Image/PDF processing
pip install Pillow reportlab opencv-python

# Utilities
pip install schedule colorama tqdm

# Visualization
pip install matplotlib seaborn plotly qrcode[pil]
```

### 🌐 **Step 5: Playwright Browsers Install**
```bash
# সব browsers install (গুরুত্বপূর্ণ!)
playwright install

# অথবা specific browsers
playwright install chromium
playwright install firefox
playwright install webkit

# Verify installation
playwright --version
```

---

## ✅ Installation Test

### 🧪 **Test Script তৈরি:**
```python
# test_installation.py
print("🧪 Testing module imports...")

modules_to_test = [
    ("playwright", "from playwright.sync_api import sync_playwright"),
    ("requests", "import requests"),
    ("beautifulsoup4", "from bs4 import BeautifulSoup"),
    ("pandas", "import pandas as pd"),
    ("numpy", "import numpy as np"),
    ("aiohttp", "import aiohttp"),
    ("aiofiles", "import aiofiles"),
    ("PIL", "from PIL import Image"),
    ("matplotlib", "import matplotlib.pyplot as plt"),
    ("tqdm", "from tqdm import tqdm"),
    ("colorama", "from colorama import Fore, init"),
]

success_count = 0
total_count = len(modules_to_test)

for module_name, import_statement in modules_to_test:
    try:
        exec(import_statement)
        print(f"✅ {module_name}: OK")
        success_count += 1
    except ImportError as e:
        print(f"❌ {module_name}: FAILED - {e}")

print(f"\n📊 Test Results: {success_count}/{total_count} modules imported successfully")

if success_count == total_count:
    print("🎉 All modules installed correctly!")
else:
    print("⚠️ Some modules failed to import")
```

### 🏃‍♂️ **Test চালান:**
```bash
python test_installation.py
```

### 🎭 **Playwright Test:**
```python
# playwright_test.py
from playwright.sync_api import sync_playwright

def test_playwright():
    print("🎭 Testing Playwright...")
    
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            page = browser.new_page()
            page.goto("https://google.com")
            
            title = page.title()
            print(f"✅ Page title: {title}")
            
            browser.close()
            print("🎉 Playwright working perfectly!")
            
    except Exception as e:
        print(f"❌ Playwright test failed: {e}")

if __name__ == "__main__":
    test_playwright()
```

```bash
python playwright_test.py
```

---

## 🔧 Requirements.txt তৈরি

### 📄 **Requirements File:**
```bash
# Current modules list তৈরি করুন
pip freeze > requirements.txt

# File check করুন
cat requirements.txt  # Linux/Mac
type requirements.txt  # Windows
```

### 📝 **Custom Requirements.txt:**
```txt
# requirements.txt

# Core Web Scraping
playwright>=1.40.0
requests>=2.31.0
beautifulsoup4>=4.12.0
lxml>=4.9.0

# Async Programming
aiohttp>=3.9.0
aiofiles>=23.2.0

# Data Processing
pandas>=2.1.0
numpy>=1.24.0
openpyxl>=3.1.0

# Image/PDF Processing
Pillow>=10.0.0
reportlab>=4.0.0
opencv-python>=4.8.0

# Visualization
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.17.0
qrcode[pil]>=7.4.0

# Utilities
schedule>=1.2.0
colorama>=0.4.6
tqdm>=4.66.0
python-dotenv>=1.0.0

# Development
pytest>=7.4.0
black>=23.9.0
```

### 📥 **Requirements থেকে Install:**
```bash
# Requirements file থেকে install
pip install -r requirements.txt

# Playwright browsers install করতে ভুলবেন না!
playwright install
```

---

## ❌ Common Problems ও Solutions

### 🚨 **Problem 1: "playwright not found"**
```bash
# Solution 1: Virtual environment activate করুন
source scraping-env/bin/activate  # Linux/Mac
scraping-env\Scripts\activate     # Windows

# Solution 2: Reinstall playwright
pip uninstall playwright
pip install playwright
playwright install
```

### 🚨 **Problem 2: "No module named 'playwright'"**
```bash
# Check virtual environment
which python  # Linux/Mac
where python   # Windows

# Should show path inside your virtual environment
# If not, activate environment again
```

### 🚨 **Problem 3: Browser download fails**
```bash
# Manual browser install
playwright install chromium --force

# Check internet connection
ping google.com

# Use different network if needed
```

### 🚨 **Problem 4: Permission denied (Linux/Mac)**
```bash
# Fix permissions
chmod +x scraping-env/bin/activate

# Or use sudo (not recommended)
sudo pip install playwright
```

### 🚨 **Problem 5: "Microsoft Visual C++ required" (Windows)**
```bash
# Download and install:
# Microsoft Visual C++ Redistributable
# https://aka.ms/vs/17/release/vc_redist.x64.exe

# Then reinstall
pip install playwright
```

---

## 🔄 Environment Management

### 📂 **Multiple Projects:**
```bash
# Project 1
mkdir project1
cd project1
python -m venv env1
source env1/bin/activate  # Linux/Mac
pip install playwright pandas

# Project 2
cd ../project2
python -m venv env2
source env2/bin/activate  # Linux/Mac
pip install playwright requests beautifulsoup4
```

### 💾 **Environment Backup:**
```bash
# Export current environment
pip freeze > requirements.txt

# Create identical environment elsewhere
pip install -r requirements.txt
playwright install
```

### 🗑️ **Environment Cleanup:**
```bash
# Deactivate environment
deactivate

# Remove environment folder
rm -rf scraping-env  # Linux/Mac
rmdir /s scraping-env  # Windows
```

---

## 🚀 Advanced Setup

### 🐳 **Docker Setup (Optional):**
```dockerfile
# Dockerfile
FROM python:3.11-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    wget \
    gnupg \
    && rm -rf /var/lib/apt/lists/*

# Install Python packages
COPY requirements.txt .
RUN pip install -r requirements.txt

# Install Playwright browsers
RUN playwright install --with-deps chromium

# Copy your code
COPY . /app
WORKDIR /app

CMD ["python", "main.py"]
```

### ⚙️ **IDE Setup (VS Code):**
```json
// .vscode/settings.json
{
    "python.defaultInterpreterPath": "./scraping-env/bin/python",
    "python.terminal.activateEnvironment": true,
    "python.linting.enabled": true,
    "python.linting.pylintEnabled": true
}
```

---

## 📊 Module Usage Examples

### 🎭 **Playwright Example:**
```python
from playwright.sync_api import sync_playwright

with sync_playwright() as p:
    browser = p.chromium.launch()
    page = browser.new_page()
    page.goto("https://example.com")
    print(page.title())
    browser.close()
```

### 📊 **Pandas Example:**
```python
import pandas as pd

# Create DataFrame
data = {'name': ['John', 'Jane'], 'age': [25, 30]}
df = pd.DataFrame(data)

# Save to CSV
df.to_csv('data.csv', index=False)
print("Data saved!")
```

### 🎨 **Matplotlib Example:**
```python
import matplotlib.pyplot as plt

# Simple plot
x = [1, 2, 3, 4, 5]
y = [2, 4, 6, 8, 10]

plt.plot(x, y)
plt.title('Simple Plot')
plt.savefig('plot.png')
print("Plot saved!")
```

### ⚡ **Async Example:**
```python
import asyncio
import aiohttp

async def fetch_data():
    async with aiohttp.ClientSession() as session:
        async with session.get('https://httpbin.org/json') as response:
            data = await response.json()
            print(data)

asyncio.run(fetch_data())
```

---

## 🎯 Next Steps

### 📚 **এখন কি করবেন:**

#### **🔰 Beginner:**
1. **[শেখার গাইড](./শেখার-গাইড.md)** পড়ুন
2. Simple scraping script লিখুন
3. Basic data processing করুন

#### **🚀 Intermediate:**
1. **[সম্পূর্ণ গাইড](./সম্পূর্ণ-playwright-গাইড.md)** পড়ুন
2. Async programming শিখুন
3. Database integration করুন

#### **🎯 Advanced:**
1. **[উন্নত কৌশল](./উন্নত-স্ক্র্যাপিং-কৌশল.md)** পড়ুন
2. Production deployment করুন
3. Monitoring setup করুন

---

## 🎉 সমাপনী

এই গাইড দিয়ে আপনি শিখেছেন:

✅ **Complete module installation process**  
✅ **Virtual environment management**  
✅ **Common problems ও solutions**  
✅ **Testing ও verification**  
✅ **Advanced setup options**  

### 🚀 **এখন আপনি ready:**
- Professional web scraping করতে
- Data processing ও analysis করতে
- Production-ready applications তৈরি করতে

**পরবর্তী step: [শেখার গাইড](./শেখার-গাইড.md) দিয়ে scraping শুরু করুন!**

**শুভ কোডিং! 📦🇧🇩**
